{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected tryout, input is set of points, it goes once through PointResnet which outputs 512 features, and once through PredictPlaneNet (fully connected prediction net for plane weights) which outputs K x 4 features, where K is number of kernels/planes used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Vision course implementation, most of it is being reused from the train.py file\n",
    "## Author: Dusan\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "from im2mesh import config, data\n",
    "from im2mesh.checkpoints import CheckpointIO\n",
    "import torch.nn as nn\n",
    "from im2mesh.encoder import fc_point_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mimicking for Shape3D and config.get_dataset() function \n",
    "## most of the setup has been copied from occupancy_networks/configs/default.yaml\n",
    "## our config is in occupancy_networks/configs/point_plane_net.yaml\n",
    "cfg = config.load_config('configs/point_plane_net_chair.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorthands\n",
    "out_dir = cfg['training']['out_dir']\n",
    "batch_size = cfg['training']['batch_size']\n",
    "# backup_every = cfg['training']['backup_every']\n",
    "input_pc_size = cfg['data']['points_subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset = config.get_dataset('train', cfg)\n",
    "val_dataset = config.get_dataset('val', cfg)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=4, shuffle=True,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=10, num_workers=4, shuffle=False,\n",
    "    collate_fn=data.collate_remove_none,\n",
    "    worker_init_fn=data.worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 3)\n",
      "(1024,)\n",
      "(256, 3)\n",
      "(256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1000]['points'].shape)\n",
    "print(train_dataset[1000]['points.occ'].shape)\n",
    "print(train_dataset[1000]['inputs'].shape)\n",
    "print(train_dataset[1000]['inputs.normals'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_point_net.FCModule(n_dim = 3, n_channels = L, n_points = input_pc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(10,input_pc_size, 3)\n",
    "labels = torch.randn(10,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3347, -0.0909, -0.2159,  0.1396],\n",
       "         [-0.1090, -0.0856,  1.1209, -0.2445],\n",
       "         [ 0.0199, -0.0127,  0.1947,  0.3696]],\n",
       "\n",
       "        [[-0.2877, -0.1224, -0.3372, -0.2113],\n",
       "         [ 0.3248,  0.0892,  0.1050,  0.1192],\n",
       "         [ 0.1984,  0.0510,  0.2718,  0.1797]],\n",
       "\n",
       "        [[-0.1797, -0.1329, -0.0260, -0.0439],\n",
       "         [ 0.2757, -0.0734,  0.0430, -0.3174],\n",
       "         [-0.2227,  0.5038,  0.1152,  0.0917]],\n",
       "\n",
       "        [[-0.2383, -0.4676, -0.2296, -0.0074],\n",
       "         [ 0.1063, -0.1447,  0.0056,  0.0880],\n",
       "         [-0.3912,  0.3647,  0.4777,  0.2043]],\n",
       "\n",
       "        [[-0.2047, -0.2737, -0.0381, -0.1202],\n",
       "         [-0.3137, -0.0314,  0.7389, -0.5613],\n",
       "         [-0.4740,  0.0540, -0.0263,  0.6056]],\n",
       "\n",
       "        [[ 0.0776,  0.1875, -0.0183, -0.0247],\n",
       "         [ 0.2516, -0.0885,  0.3075, -0.0517],\n",
       "         [ 0.0156,  0.2411, -0.0370,  0.2593]],\n",
       "\n",
       "        [[-0.6512,  0.0458,  0.0349, -0.2127],\n",
       "         [ 0.2231, -0.0480,  0.3709,  0.1511],\n",
       "         [ 0.0347,  0.4154,  0.2373,  0.5027]],\n",
       "\n",
       "        [[-0.1847, -0.2226,  0.4261,  0.1109],\n",
       "         [-0.0528, -0.0868,  0.2055,  0.2415],\n",
       "         [ 0.0439,  0.5821,  0.6330,  0.3931]],\n",
       "\n",
       "        [[-0.3829, -0.2329,  0.0320, -0.2290],\n",
       "         [ 0.0636,  0.1402,  0.2789, -0.0161],\n",
       "         [-0.1357,  0.6571, -0.0336, -0.1710]],\n",
       "\n",
       "        [[-0.6422, -0.3029, -0.2322, -0.1774],\n",
       "         [ 0.2631,  0.2503,  0.1576, -0.4069],\n",
       "         [ 0.0896,  0.1133, -0.1450, -0.2381]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input).view(10,3, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
